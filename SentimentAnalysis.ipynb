{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26909,
     "status": "ok",
     "timestamp": 1745383314695,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "fPY31b1zcIi9",
    "outputId": "b2e766ee-6851-40da-df6f-949584f2cb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9086,
     "status": "ok",
     "timestamp": 1745383323791,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "_QPx-pefcfca",
    "outputId": "8a98e7c9-e9f6-4996-ec96-7a23595e41f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "!pip install vaderSentiment\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1796,
     "status": "ok",
     "timestamp": 1745383375074,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "Bayuiichcn9Z",
    "outputId": "394cd975-b5cd-4060-e642-2ee1d1f39311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 351\n",
      "Missing Values:\n",
      " id                  0\n",
      "reviewer_name       0\n",
      "review_text         0\n",
      "platform            0\n",
      "likes               0\n",
      "timestamp           0\n",
      "discovery_source    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"the_ordinary_reviews_final02.xlsx\")\n",
    "print(f\"Total Records: {len(df)}\")\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1745383376757,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "OSNVecaA1XhD",
    "outputId": "c1be4d53-1fd6-4c81-df3b-dde7b096ba3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicate Reviews: 7\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = df.duplicated(subset=['review_text']).sum()\n",
    "print(f\"Total Duplicate Reviews: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745383378591,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "B0MYmdlb2Rb8",
    "outputId": "a0df0cb9-942f-41e8-8dd7-8b6a6a073a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records after removal of duplicates: 344\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['review_text'])\n",
    "print(f\"Total Records after removal of duplicates: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745383395295,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "WK0sb5CK2XXb"
   },
   "outputs": [],
   "source": [
    "df = df[df['review_text'].str.len() > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1745383397358,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "Sa7dqNnW6U2R",
    "outputId": "02514b6b-a292-424f-c1c6-2aa5d4a95316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is cleaned and saved as'cleaned_reviews.xlsx'\n"
     ]
    }
   ],
   "source": [
    "df.to_excel('/cleaned_reviews.xlsx', index=False)\n",
    "print(\"Dataset is cleaned and saved as'cleaned_reviews.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1745384434694,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "k-ynP04j_0F9",
    "outputId": "ce8683b7-da8d-4358-df81-97113ae7e43b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset is VADER classified and saved as'vader_custom_scored_reviews.xlsx'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vader_label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "vader_label\n",
       "Positive    252\n",
       "Negative     50\n",
       "Neutral      41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "df = pd.read_excel(\"cleaned_reviews.xlsx\")\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def preprocess_phrases(text):\n",
    "    text = str(text).lower()\n",
    "    text = text.replace(\"game changer for me\", \"game_changer_for_me\")\n",
    "    text = text.replace(\"total game changer\", \"total_game_changer\")\n",
    "    text = text.replace(\"go to for me\", \"go_to_for_me\")\n",
    "    text = text.replace(\"go-to\", \"go_to\")\n",
    "    text = text.replace(\"go to\", \"go_to\")\n",
    "    text = text.replace(\"no side effects\", \"no_side_effects\")\n",
    "    text = text.replace(\"blown away\", \"blown_away\")\n",
    "    text = text.replace(\"not in love\", \"not_in_love\")\n",
    "    text = text.replace(\"not sure\", \"not_sure\")\n",
    "    text = text.replace(\"not convinced by the hype\", \"not_convinced_by_the_hype\")\n",
    "    text = text.replace(\"still unsure\", \"still_unsure\")\n",
    "    text = text.replace(\"no glow\", \"no_glow\")\n",
    "    text = text.replace(\"didnâ€™t cause any issues\", \"no_issues\")\n",
    "    text = text.replace(\"kind of average\", \"kind_of_average\")\n",
    "    text = text.replace(\"not amazing\", \"not_amazing\")\n",
    "    text = text.replace(\"not terrible\", \"not_terrible\")\n",
    "    text = text.replace(\"too heavy\", \"too_heavy\")\n",
    "    text = text.replace(\"a bit overpriced\", \"overpriced\")\n",
    "    return text\n",
    "\n",
    "# Custom lexicon update (underscore versions for preprocessed phrases)\n",
    "analyzer.lexicon.update({\n",
    "    \"game_changer_for_me\": 4.0,\n",
    "    \"go_to\": 4.0,\n",
    "    \"go_to_for_me\": 4.0,\n",
    "    \"no_side_effects\": 1.0,\n",
    "    \"amazing\": 4.0,\n",
    "    \"broke\": -3.0,\n",
    "    \"blown_away\": 3.0,\n",
    "    \"absorbs\": 3.0,\n",
    "    \"okay\": 0,\n",
    "    \"not_in_love\": 0,\n",
    "    \"calmer\": 3.0,\n",
    "    \"helped\": 3.0,\n",
    "    \"not_sure\": 0,\n",
    "    \"average\": 0,\n",
    "    \"total_game_changer\": 4.0,\n",
    "     \"no_side_effects\": 1.0,\n",
    "    \"no_glow\": -1.5,\n",
    "    \"still_unsure\": 0,\n",
    "    \"no_issues\": 1.0 ,\n",
    "     \"not_sure\": 0,\n",
    "    \"not_amazing\": 0,\n",
    "    \"not_terrible\": 0,\n",
    "    \"kind_of_average\": 0,\n",
    "    \"too_heavy\" : -2.0,\n",
    "    \"overpriced\": -2.0,\n",
    "    \"disappointed\": -2.5,\n",
    "    \"expected more\": -1.0\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "df['processed_text'] = df['review_text'].apply(preprocess_phrases)\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    scores = analyzer.polarity_scores(str(text))\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif compound <= -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    return pd.Series([compound, sentiment])\n",
    "\n",
    "df[['vader_polarity', 'vader_label']] = df['processed_text'].apply(get_sentiment_scores)\n",
    "\n",
    "df.to_excel(\"vader_custom_scored_reviews.xlsx\", index=False)\n",
    "print(\"Cleaned Dataset is VADER classified and saved as'vader_custom_scored_reviews.xlsx'\")\n",
    "df['vader_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1745383402137,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "Br0pdX8hAyhs"
   },
   "outputs": [],
   "source": [
    "#MODEL DEVELOPMENT\n",
    "\n",
    "df = pd.read_excel(\"training_set.xlsx\")\n",
    "df = df[['review_text', 'verified_label']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1745384391093,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "dj5eclfeHZAo"
   },
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['review_text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1745383410317,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "aCVCtJUKEgPm"
   },
   "outputs": [],
   "source": [
    "label_map = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "df['label'] = df['verified_label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1745383412011,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "CVx-xUFOEkif"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "X_raw = df['cleaned_text']\n",
    "y     = df['label']\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test  = vectorizer.transform(X_test_raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1745383414545,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "nJHbK71kErk5",
    "outputId": "452e8049-1484-4ee8-f537-8f8365067613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Accuracy: 72.07%\n",
      "\n",
      "ðŸ” Detailed Performance Metrics:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.735     0.735     0.735        34\n",
      "     Neutral      0.800     0.541     0.645        37\n",
      "    Positive      0.673     0.875     0.761        40\n",
      "\n",
      "    accuracy                          0.721       111\n",
      "   macro avg      0.736     0.717     0.714       111\n",
      "weighted avg      0.734     0.721     0.714       111\n",
      "\n",
      "NaÃ¯ve Bayes Accuracy: 60.87%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.60      0.43      0.50         7\n",
      "     Neutral       0.80      0.50      0.62         8\n",
      "    Positive       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.61        23\n",
      "   macro avg       0.65      0.60      0.59        23\n",
      "weighted avg       0.65      0.61      0.60        23\n",
      "\n",
      "SVM Accuracy: 43.48%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.38      0.43      0.40         7\n",
      "     Neutral       0.43      0.38      0.40         8\n",
      "    Positive       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.43        23\n",
      "   macro avg       0.43      0.43      0.43        23\n",
      "weighted avg       0.44      0.43      0.43        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "nb_model  = MultinomialNB()\n",
    "svm_model = LinearSVC(max_iter=5000)\n",
    "nb_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "df_model = pd.read_excel(\"training_set.xlsx\")\n",
    "df_model = df_model[['review_text', 'verified_label']].dropna()\n",
    "\n",
    "df_vader = pd.read_excel(\"vader_custom_scored_reviews.xlsx\")\n",
    "df_vader = df_vader[['review_text', 'vader_label']]\n",
    "\n",
    "df = pd.merge(df_model, df_vader, on='review_text', how='inner')\n",
    "accuracy = accuracy_score(df['verified_label'], df['vader_label'])\n",
    "print(f\"VADER Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nðŸ” Detailed Performance Metrics:\\n\")\n",
    "print(classification_report(df['verified_label'], df['vader_label'], digits=3))\n",
    "\n",
    "for name, model in [('NaÃ¯ve Bayes', nb_model), ('SVM', svm_model)]:\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, preds) * 100:.2f}%\")\n",
    "    print(classification_report(\n",
    "        y_test, preds,\n",
    "        target_names=['Negative','Neutral','Positive']\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5833,
     "status": "ok",
     "timestamp": 1745383428013,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "pczp9nvLT7Gm",
    "outputId": "43b89f45-dd34-4436-f011-066b9f1ab854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit pyngrok openpyxl scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1745384339598,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "Wc7yi7xP16tk"
   },
   "outputs": [],
   "source": [
    "with open(\"app.py\", \"w\") as f:\n",
    "    f.write('''\\\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tab1, tab2 = st.tabs([\"Sentiment Analysis On Social Media Reviews on the brand, The Ordinary.\", \"Model Comparison\"])\n",
    "\n",
    "with tab1:\n",
    "    st.markdown(\"<h1 style='text-align: center; color: #B9D9EB; font-family: monospace;'>Sentiment Analysis Dashboard</h1>\", unsafe_allow_html=True)\n",
    "    df = pd.read_excel(\"vader_custom_scored_reviews.xlsx\")\n",
    "\n",
    "    df['vader_label'] = df['vader_label'].str.lower()\n",
    "\n",
    "    sentiment_counts = df['vader_label'].value_counts()\n",
    "    labels = sentiment_counts.index.tolist()\n",
    "\n",
    "    fig = px.pie(\n",
    "        names=labels,\n",
    "        values=sentiment_counts.values,\n",
    "        color=labels,\n",
    "        color_discrete_map={\n",
    "            'positive': '#ffabab',\n",
    "            'neutral': '#0068c9',\n",
    "            'negative': '#83c8ff'\n",
    "        },\n",
    "        title=\"Distribution of Sentiments in Reviews\"\n",
    "    )\n",
    "\n",
    "    fig.update_traces(textinfo='percent+label')\n",
    "    fig.update_layout(title_font_size=20)\n",
    "\n",
    "    st.plotly_chart(fig)\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"\n",
    "    The sentiment analysis reveals a predominantly positive perception of the brand, with 73.5% of customer reviews expressing positive sentiment.\n",
    "    While negative reviews account for 14.6% and neutral reviews 12.0%, the overwhelming positive feedback indicates **strong overall customer satisfaction.**\n",
    "\n",
    "    Addressing the concerns raised in the negative reviews remains important for continuous improvement.\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Platform vs sentiment\n",
    "    platform_sentiment = df.groupby(['platform', 'vader_label']).size().unstack().fillna(0)\n",
    "    st.write(\"### Sentiment Distribution by Platform\")\n",
    "    st.bar_chart(platform_sentiment)\n",
    "\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"\n",
    "    Across Facebook, Instagram, and Twitter, the sentiment towards the skincare brand shows a consistent pattern with the highest volume of positive sentiment,\n",
    "    followed by neutral, and then negative sentiment having the lowest volume.\n",
    "    Facebook and Twitter show a similar overall volume of mentions, while Instagram has a notably lower volume across all sentiment categories.\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Time vs sentiment\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "    df['month'] = df['timestamp'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "    monthly_sentiment = df.groupby(['month', 'vader_label']).size().unstack().fillna(0)\n",
    "\n",
    "    st.write(\"### Sentiment Over Time\")\n",
    "    st.line_chart(monthly_sentiment)\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"\n",
    "    The sentiment towards the skincare brand from **2018 to 2024** has been predominantly **positive**, with frequent noticeable peaks.\n",
    "    **Negative sentiment** remains consistently low, showing only occasional, mild spikes.\n",
    "    Meanwhile, **neutral sentiment** fluctuates modestly over time.\n",
    "    Overall, this indicates a generally **favorable public perception** of the brand, with periods of increased engagement likely linked to campaigns, events, or product launches.\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Discovery source vs sentiment\n",
    "    discovery_sentiment = df.groupby(['discovery_source', 'vader_label']).size().unstack().fillna(0)\n",
    "    discovery_sentiment = discovery_sentiment.loc[discovery_sentiment.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "    st.markdown(\"### Sentiment by Discovery Source\")\n",
    "    st.bar_chart(discovery_sentiment)\n",
    "\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"\n",
    "    Among all discovery sources, **TikTok**, **Search Engines**, and **Influencers** brought in the highest number of total reviews,\n",
    "    with **TikTok** and **Influencers** showing a strong skew toward **positive sentiment**.\n",
    "\n",
    "    Interestingly, sources like **Friends** and **In-store experiences** also led to a large number of reviews, but the sentiment distribution there was more mixed.\n",
    "\n",
    "    This suggests that **social media platforms and influencer marketing** not only drive high engagement but also tend to result in\n",
    "    **more favorable customer perceptions**.\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Review Length by Sentiment\n",
    "    st.markdown(\"### Review Length by Sentiment\")\n",
    "    df['review_length'] = df['processed_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    fig1 = px.box(df,\n",
    "                  x='vader_label',\n",
    "                  y='review_length',\n",
    "                  color='vader_label',\n",
    "                  color_discrete_map={\n",
    "                      \"Positive\": \"#8dd3c7\",\n",
    "                      \"Neutral\": \"#ffffb3\",\n",
    "                      \"Negative\": \"#fb8072\"\n",
    "                  },\n",
    "                  title=\"How Review Length Varies with Sentiment\")\n",
    "\n",
    "    fig1.update_layout(\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font_color='white',\n",
    "        title_font_size=18\n",
    "    )\n",
    "    st.plotly_chart(fig1, use_container_width=True)\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"\n",
    "    Positive reviews tend to be longer and receive more likes, suggesting that detailed, enthusiastic feedback resonates well with others.\n",
    "    Negative reviews, while shorter on average, also garner attention, possibly due to their emotional impact.\n",
    "    Neutral reviews are typically brief and receive the least engagement.\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Likes by Sentiment\n",
    "    st.markdown(\"### Likes by Sentiment\")\n",
    "\n",
    "    fig2 = px.box(df,\n",
    "                  x='vader_label',\n",
    "                  y='likes',\n",
    "                  color='vader_label',\n",
    "                  color_discrete_map={\n",
    "                      \"Positive\": \"#8dd3c7\",\n",
    "                      \"Neutral\": \"#ffffb3\",\n",
    "                      \"Negative\": \"#fb8072\"\n",
    "                  },\n",
    "                  title=\"How Likes Vary with Sentiment\")\n",
    "\n",
    "    fig2.update_layout(\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font_color='white',\n",
    "        title_font_size=18\n",
    "    )\n",
    "    st.plotly_chart(fig2, use_container_width=True)\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"\n",
    "    Content with strong sentiment (positive or negative) is generally more engaging and tends to receive more likes than neutral content.\n",
    "    This reinforces the idea that emotional tone plays a significant role in social media engagement.\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"### Most Liked Reviews by Sentiment\")\n",
    "\n",
    "    df = df.dropna(subset=['review_text', 'vader_label', 'likes'])\n",
    "    df['likes'] = pd.to_numeric(df['likes'], errors='coerce')\n",
    "    df = df.dropna(subset=['likes'])\n",
    "    df['vader_label'] = df['vader_label'].str.capitalize()\n",
    "\n",
    "    for sentiment in ['Positive', 'Neutral', 'Negative']:\n",
    "        st.write(f\"#### {sentiment} Reviews\")\n",
    "        top_reviews = df[df['vader_label'] == sentiment].sort_values(by='likes', ascending=False).head(3)\n",
    "        st.dataframe(top_reviews[['review_text', 'likes', 'platform']])\n",
    "\n",
    "\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"The most liked reviews across all sentiments are detailed and emotionally expressive.\n",
    "    Positive reviews highlight product effectiveness, while top negative reviews are often tied to skin reactions.\n",
    "      This suggests users resonate most with personal experiences that feel relatable or extreme.\"\"\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"### Average Sentiment Score by Discovery Source\")\n",
    "    source_sentiment = df.groupby('discovery_source')['vader_polarity'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "    fig = px.bar(\n",
    "        source_sentiment,\n",
    "        x='discovery_source',\n",
    "        y='vader_polarity',\n",
    "        title=\"Average Sentiment Score by Discovery Source\",\n",
    "        labels={'vader_polarity': 'Avg Sentiment Score', 'discovery_source': 'Discovery Source'},\n",
    "        color='vader_polarity',\n",
    "        color_continuous_scale='RdYlGn'\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    st.plotly_chart(fig)\n",
    "    st.markdown(\"### Conclusion\")\n",
    "    st.write(\"\"\"Marketers and brands might want to focus more on Social Media, Reddit, and Search Engines to improve perception and engagement.\n",
    "    Beauty Blogs and Ads may need reassessment or different strategies to improve their public perception.\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tab2:\n",
    "    st.markdown(\"### Model Accuracy Comparison\")\n",
    "    st.write(\"This section compares the performance of different sentiment classification models:\")\n",
    "\n",
    "    # Create a small DataFrame of your accuracy scores\n",
    "    accuracy_df = pd.DataFrame({\n",
    "        \"Model\": [\"VADER\", \"Naive Bayes\", \"SVM\"],\n",
    "        \"Accuracy\": [71.17, 60.87, 43.48]\n",
    "    })\n",
    "\n",
    "    # Build the Plotly bar chart\n",
    "    fig_acc = px.bar(\n",
    "        accuracy_df,\n",
    "        x=\"Model\",\n",
    "        y=\"Accuracy\",\n",
    "        text=\"Accuracy\",\n",
    "        range_y=[0, 100],\n",
    "        color=\"Model\",\n",
    "        color_discrete_map={\"VADER\": \"#636EFA\", \"Naive Bayes\": \"#EF553B\", \"SVM\": \"#00CC96\"}\n",
    "    )\n",
    "\n",
    "    fig_acc.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\n",
    "    fig_acc.update_layout(\n",
    "        yaxis_title=\"Accuracy (%)\",\n",
    "        xaxis_title=\"Model\",\n",
    "        title=\"Model Accuracy Comparison\",\n",
    "        showlegend=False,\n",
    "        uniformtext_minsize=8,\n",
    "        uniformtext_mode='hide'\n",
    "    )\n",
    "\n",
    "    st.plotly_chart(fig_acc, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"### Detailed Metrics\")\n",
    "\n",
    "    vader_metrics = \"\"\"\n",
    "| Class     | Precision | Recall | F1-score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "| Negative  | 0.735     | 0.735  | 0.735    | 34      |\n",
    "| Neutral   | 0.826     | 0.514  | 0.633    | 37      |\n",
    "| Positive  | 0.648     | 0.875  | 0.745    | 40      |\n",
    "| **Avg (W)**| 0.734    | 0.712  | 0.705    | 111     |\n",
    "    \"\"\"\n",
    "\n",
    "    nb_metrics = \"\"\"\n",
    "| Class     | Precision | Recall | F1-score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "| Negative  | 0.60      | 0.43   | 0.50     | 7       |\n",
    "| Neutral   | 0.80      | 0.50   | 0.62     | 8       |\n",
    "| Positive  | 0.54      | 0.88   | 0.67     | 8       |\n",
    "| **Avg (W)**| 0.65     | 0.61   | 0.60     | 23      |\n",
    "    \"\"\"\n",
    "\n",
    "    svm_metrics = \"\"\"\n",
    "| Class     | Precision | Recall | F1-score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "| Negative  | 0.38      | 0.43   | 0.40     | 7       |\n",
    "| Neutral   | 0.43      | 0.38   | 0.40     | 8       |\n",
    "| Positive  | 0.50      | 0.50   | 0.50     | 8       |\n",
    "| **Avg (W)**| 0.44     | 0.43   | 0.43     | 23      |\n",
    "    \"\"\"\n",
    "\n",
    "    st.markdown(\"#### VADER\")\n",
    "    st.markdown(vader_metrics)\n",
    "\n",
    "    st.markdown(\"#### Naive Bayes\")\n",
    "    st.markdown(nb_metrics)\n",
    "\n",
    "    st.markdown(\"#### SVM\")\n",
    "    st.markdown(svm_metrics)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### Summary\")\n",
    "    st.write(\"\"\"\n",
    "VADER performed best overall, especially with Positive and Negative reviews, thanks to its sentiment-focused lexicon.\n",
    "Naive Bayes had good recall on Positive but struggled with Negative.\n",
    "SVM underperformed on this dataset, likely due to the size of the dataset.\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5904,
     "status": "ok",
     "timestamp": 1745384339507,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "XeDn8bLtxOdI",
    "outputId": "9a99db45-a70f-4285-af2e-d2139e23c9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
      "ðŸŒ Streamlit app is live at: NgrokTunnel: \"https://2650-34-73-190-253.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1745389291743,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "LF5DhxU7I2Ee",
    "outputId": "a587af04-85d8-409b-a67a-fd8e9b019c20"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_1d1013bd-16c6-4b0d-b4fe-e74c4d24c249\", \"requirements.txt\", 93)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"\\\n",
    "streamlit\n",
    "pyngrok\n",
    "pandas\n",
    "nltk\n",
    "matplotlib\n",
    "seaborn\n",
    "plotly\n",
    "scikit-learn\n",
    "openpyxl\n",
    "vaderSentiment\n",
    "\"\"\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"requirements.txt\")\n",
    "files.download(\"app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745389294135,
     "user": {
      "displayName": "Chaitra",
      "userId": "03214113649097688221"
     },
     "user_tz": -330
    },
    "id": "5Mp_0wcCKng8",
    "outputId": "4f13e3fc-6936-459a-a7f9-a5949dbcbf1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'requirements.txt',\n",
       " 'svm_model.pkl',\n",
       " 'app.py',\n",
       " 'drive',\n",
       " 'vectorizer.pkl',\n",
       " 'vader_custom_scored_reviews.xlsx',\n",
       " 'naive_bayes_model.pkl',\n",
       " 'sample_data']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg3_IRXmN90r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9imWi5ldCsQNq86w/yIE/",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
